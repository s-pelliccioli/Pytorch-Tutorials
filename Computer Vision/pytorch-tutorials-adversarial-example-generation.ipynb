{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from __future__ import print_function\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# NOTE: This is a hack to get around \"User-agent\" limitations when downloading MNIST datasets\n#       see, https://github.com/pytorch/vision/issues/3497 for more information\nfrom six.moves import urllib\nopener = urllib.request.build_opener()\nopener.addheaders = [('User-agent', 'Mozilla/5.0')]\nurllib.request.install_opener(opener)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-09T21:32:27.733759Z","iopub.execute_input":"2022-02-09T21:32:27.734329Z","iopub.status.idle":"2022-02-09T21:32:29.295471Z","shell.execute_reply.started":"2022-02-09T21:32:27.734235Z","shell.execute_reply":"2022-02-09T21:32:29.293952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epsilons = [0, .05, .1, .15, .2, .25, .3]\npretrained_model = \"/kaggle/input/Lenet-mnist-model/lenet_mnist_model.pth\"\nuse_cuda=True","metadata":{"execution":{"iopub.status.busy":"2022-02-09T21:43:16.493595Z","iopub.execute_input":"2022-02-09T21:43:16.494147Z","iopub.status.idle":"2022-02-09T21:43:16.498627Z","shell.execute_reply.started":"2022-02-09T21:43:16.494111Z","shell.execute_reply":"2022-02-09T21:43:16.497675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LeNet Model definition\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=1)\n\n# MNIST Test dataset and dataloader declaration\ntest_loader = torch.utils.data.DataLoader(\n    datasets.MNIST('../data', train=False, download=True, transform=transforms.Compose([\n            transforms.ToTensor(),\n            ])),\n        batch_size=1, shuffle=True)\n\n# Define what device we are using\nprint(\"CUDA Available: \",torch.cuda.is_available())\ndevice = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n\n# Initialize the network\nmodel = Net().to(device)\n\n# Load the pretrained model\nmodel.load_state_dict(torch.load(pretrained_model, map_location='cpu'))\n\n# Set the model in evaluation mode. In this case this is for the Dropout layers\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2022-02-09T21:43:18.719816Z","iopub.execute_input":"2022-02-09T21:43:18.720345Z","iopub.status.idle":"2022-02-09T21:43:18.752135Z","shell.execute_reply.started":"2022-02-09T21:43:18.720305Z","shell.execute_reply":"2022-02-09T21:43:18.751399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# FGSM attack code\ndef fgsm_attack(image, epsilon, data_grad):\n    # Collect the element-wise sign of the data gradient\n    sign_data_grad = data_grad.sign()\n    # Create the perturbed image by adjusting each pixel of the input image\n    perturbed_image = image + epsilon*sign_data_grad\n    # Adding clipping to maintain [0,1] range\n    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n    # Return the perturbed image\n    return perturbed_image","metadata":{"execution":{"iopub.status.busy":"2022-02-09T21:44:30.918023Z","iopub.execute_input":"2022-02-09T21:44:30.918275Z","iopub.status.idle":"2022-02-09T21:44:30.922655Z","shell.execute_reply.started":"2022-02-09T21:44:30.918247Z","shell.execute_reply":"2022-02-09T21:44:30.921966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test( model, device, test_loader, epsilon ):\n\n    # Accuracy counter\n    correct = 0\n    adv_examples = []\n\n    # Loop over all examples in test set\n    for data, target in test_loader:\n\n        # Send the data and label to the device\n        data, target = data.to(device), target.to(device)\n\n        # Set requires_grad attribute of tensor. Important for Attack\n        data.requires_grad = True\n\n        # Forward pass the data through the model\n        output = model(data)\n        init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n\n        # If the initial prediction is wrong, dont bother attacking, just move on\n        if init_pred.item() != target.item():\n            continue\n\n        # Calculate the loss\n        loss = F.nll_loss(output, target)\n\n        # Zero all existing gradients\n        model.zero_grad()\n\n        # Calculate gradients of model in backward pass\n        loss.backward()\n\n        # Collect datagrad\n        data_grad = data.grad.data\n\n        # Call FGSM Attack\n        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n\n        # Re-classify the perturbed image\n        output = model(perturbed_data)\n\n        # Check for success\n        final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n        if final_pred.item() == target.item():\n            correct += 1\n            # Special case for saving 0 epsilon examples\n            if (epsilon == 0) and (len(adv_examples) < 5):\n                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n        else:\n            # Save some adv examples for visualization later\n            if len(adv_examples) < 5:\n                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n\n    # Calculate final accuracy for this epsilon\n    final_acc = correct/float(len(test_loader))\n    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n\n    # Return the accuracy and an adversarial example\n    return final_acc, adv_examples","metadata":{"execution":{"iopub.status.busy":"2022-02-09T21:46:32.511435Z","iopub.execute_input":"2022-02-09T21:46:32.51171Z","iopub.status.idle":"2022-02-09T21:46:32.524084Z","shell.execute_reply.started":"2022-02-09T21:46:32.511678Z","shell.execute_reply":"2022-02-09T21:46:32.523343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracies = []\nexamples = []\n\n# Run test for each epsilon\nfor eps in epsilons:\n    acc, ex = test(model, device, test_loader, eps)\n    accuracies.append(acc)\n    examples.append(ex)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T21:47:09.164335Z","iopub.execute_input":"2022-02-09T21:47:09.16489Z","iopub.status.idle":"2022-02-09T21:49:55.614172Z","shell.execute_reply.started":"2022-02-09T21:47:09.16485Z","shell.execute_reply":"2022-02-09T21:49:55.612696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(5,5))\nplt.plot(epsilons, accuracies, \"*-\")\nplt.yticks(np.arange(0, 1.1, step=0.1))\nplt.xticks(np.arange(0, .35, step=0.05))\nplt.title(\"Accuracy vs Epsilon\")\nplt.xlabel(\"Epsilon\")\nplt.ylabel(\"Accuracy\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-09T21:50:41.055321Z","iopub.execute_input":"2022-02-09T21:50:41.055586Z","iopub.status.idle":"2022-02-09T21:50:41.230625Z","shell.execute_reply.started":"2022-02-09T21:50:41.055559Z","shell.execute_reply":"2022-02-09T21:50:41.229804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot several examples of adversarial samples at each epsilon\ncnt = 0\nplt.figure(figsize=(8,10))\nfor i in range(len(epsilons)):\n    for j in range(len(examples[i])):\n        cnt += 1\n        plt.subplot(len(epsilons),len(examples[0]),cnt)\n        plt.xticks([], [])\n        plt.yticks([], [])\n        if j == 0:\n            plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n        orig,adv,ex = examples[i][j]\n        plt.title(\"{} -> {}\".format(orig, adv))\n        plt.imshow(ex, cmap=\"gray\")\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-09T21:52:13.452837Z","iopub.execute_input":"2022-02-09T21:52:13.453553Z","iopub.status.idle":"2022-02-09T21:52:15.013085Z","shell.execute_reply.started":"2022-02-09T21:52:13.453508Z","shell.execute_reply":"2022-02-09T21:52:15.012441Z"},"trusted":true},"execution_count":null,"outputs":[]}]}