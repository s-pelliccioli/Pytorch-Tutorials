{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\n\n# PyTorch TensorBoard support\nfrom torch.utils.tensorboard import SummaryWriter\nfrom datetime import datetime","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-03T21:35:06.631277Z","iopub.execute_input":"2022-02-03T21:35:06.631888Z","iopub.status.idle":"2022-02-03T21:35:08.757321Z","shell.execute_reply.started":"2022-02-03T21:35:06.631773Z","shell.execute_reply":"2022-02-03T21:35:08.756268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose(\n    [transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))])\n\n# Create datasets for training & validation, download if necessary\ntraining_set = torchvision.datasets.FashionMNIST('./data', train=True, transform=transform, download=True)\nvalidation_set = torchvision.datasets.FashionMNIST('./data', train=False, transform=transform, download=True)\n\n# Create data loaders for our datasets; shuffle for training, not for validation\ntraining_loader = torch.utils.data.DataLoader(training_set, batch_size=4, shuffle=True, num_workers=2)\nvalidation_loader = torch.utils.data.DataLoader(validation_set, batch_size=4, shuffle=False, num_workers=2)\n\n# Class labels\nclasses = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n\n# Report split sizes\nprint('Training set has {} instances'.format(len(training_set)))\nprint('Validation set has {} instances'.format(len(validation_set)))","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:36:20.0008Z","iopub.execute_input":"2022-02-03T21:36:20.001219Z","iopub.status.idle":"2022-02-03T21:36:27.480497Z","shell.execute_reply.started":"2022-02-03T21:36:20.001182Z","shell.execute_reply":"2022-02-03T21:36:27.479587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# Helper function for inline image display\ndef matplotlib_imshow(img, one_channel=False):\n    if one_channel:\n        img = img.mean(dim=0)\n    img = img / 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    if one_channel:\n        plt.imshow(npimg, cmap=\"Greys\")\n    else:\n        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n\ndataiter = iter(training_loader)\nimages, labels = dataiter.next()\n\n# Create a grid from the images and show them\nimg_grid = torchvision.utils.make_grid(images)\nmatplotlib_imshow(img_grid, one_channel=True)\nprint('  '.join(classes[labels[j]] for j in range(4)))","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:37:02.133517Z","iopub.execute_input":"2022-02-03T21:37:02.134047Z","iopub.status.idle":"2022-02-03T21:37:02.584765Z","shell.execute_reply.started":"2022-02-03T21:37:02.134005Z","shell.execute_reply":"2022-02-03T21:37:02.583857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\n# PyTorch models inherit from torch.nn.Module\nclass GarmentClassifier(nn.Module):\n    def __init__(self):\n        super(GarmentClassifier, self).__init__()\n        self.conv1 = nn.Conv2d(1, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 4 * 4)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n\nmodel = GarmentClassifier()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:37:33.532225Z","iopub.execute_input":"2022-02-03T21:37:33.5329Z","iopub.status.idle":"2022-02-03T21:37:33.547796Z","shell.execute_reply.started":"2022-02-03T21:37:33.53286Z","shell.execute_reply":"2022-02-03T21:37:33.546934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_fn = torch.nn.CrossEntropyLoss()\n\n# NB: Loss functions expect data in batches, so we're creating batches of 4\n# Represents the model's confidence in each of the 10 classes for a given input\ndummy_outputs = torch.rand(4, 10)\n# Represents the correct class among the 10 being tested\ndummy_labels = torch.tensor([1, 5, 3, 7])\n\nprint(dummy_outputs)\nprint(dummy_labels)\n\nloss = loss_fn(dummy_outputs, dummy_labels)\nprint('Total loss for this batch: {}'.format(loss.item()))","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:38:05.731678Z","iopub.execute_input":"2022-02-03T21:38:05.732791Z","iopub.status.idle":"2022-02-03T21:38:05.772457Z","shell.execute_reply.started":"2022-02-03T21:38:05.732729Z","shell.execute_reply":"2022-02-03T21:38:05.771854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Optimizers specified in the torch.optim package\noptimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:38:45.084494Z","iopub.execute_input":"2022-02-03T21:38:45.08495Z","iopub.status.idle":"2022-02-03T21:38:45.088944Z","shell.execute_reply.started":"2022-02-03T21:38:45.084901Z","shell.execute_reply":"2022-02-03T21:38:45.088203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_one_epoch(epoch_index, tb_writer):\n    running_loss = 0.\n    last_loss = 0.\n\n    # Here, we use enumerate(training_loader) instead of\n    # iter(training_loader) so that we can track the batch\n    # index and do some intra-epoch reporting\n    for i, data in enumerate(training_loader):\n        # Every data instance is an input + label pair\n        inputs, labels = data\n\n        # Zero your gradients for every batch!\n        optimizer.zero_grad()\n\n        # Make predictions for this batch\n        outputs = model(inputs)\n\n        # Compute the loss and its gradients\n        loss = loss_fn(outputs, labels)\n        loss.backward()\n\n        # Adjust learning weights\n        optimizer.step()\n\n        # Gather data and report\n        running_loss += loss.item()\n        if i % 1000 == 999:\n            last_loss = running_loss / 1000 # loss per batch\n            print('  batch {} loss: {}'.format(i + 1, last_loss))\n            tb_x = epoch_index * len(training_loader) + i + 1\n            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n            running_loss = 0.\n\n    return last_loss","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:40:41.26254Z","iopub.execute_input":"2022-02-03T21:40:41.26335Z","iopub.status.idle":"2022-02-03T21:40:41.271241Z","shell.execute_reply.started":"2022-02-03T21:40:41.263302Z","shell.execute_reply":"2022-02-03T21:40:41.270535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initializing in a separate cell so we can easily add more epochs to the same run\ntimestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\nwriter = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\nepoch_number = 0\n\nEPOCHS = 5\n\nbest_vloss = 1_000_000.\n\nfor epoch in range(EPOCHS):\n    print('EPOCH {}:'.format(epoch_number + 1))\n\n    # Make sure gradient tracking is on, and do a pass over the data\n    model.train(True)\n    avg_loss = train_one_epoch(epoch_number, writer)\n\n    # We don't need gradients on to do reporting\n    model.train(False)\n\n    running_vloss = 0.0\n    for i, vdata in enumerate(validation_loader):\n        vinputs, vlabels = vdata\n        voutputs = model(vinputs)\n        vloss = loss_fn(voutputs, vlabels)\n        running_vloss += vloss\n\n    avg_vloss = running_vloss / (i + 1)\n    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n\n    # Log the running loss averaged per batch\n    # for both training and validation\n    writer.add_scalars('Training vs. Validation Loss',\n                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n                    epoch_number + 1)\n    writer.flush()\n\n    # Track best performance, and save the model's state\n    if avg_vloss < best_vloss:\n        best_vloss = avg_vloss\n        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n        torch.save(model.state_dict(), model_path)\n\n    epoch_number += 1","metadata":{},"execution_count":null,"outputs":[]}]}