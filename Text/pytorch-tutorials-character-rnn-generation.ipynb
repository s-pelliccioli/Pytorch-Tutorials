{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from __future__ import unicode_literals, print_function, division\nfrom io import open\nimport glob\nimport os\nimport unicodedata\nimport string\n\nall_letters = string.ascii_letters + \" .,;'-\"\nn_letters = len(all_letters) + 1 # Plus EOS marker\n\ndef findFiles(path): return glob.glob(path)\n\n# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\ndef unicodeToAscii(s):\n    return ''.join(\n        c for c in unicodedata.normalize('NFD', s)\n        if unicodedata.category(c) != 'Mn'\n        and c in all_letters\n    )\n\n# Read a file and split into lines\ndef readLines(filename):\n    with open(filename, encoding='utf-8') as some_file:\n        return [unicodeToAscii(line.strip()) for line in some_file]\n\n# Build the category_lines dictionary, a list of lines per category\ncategory_lines = {}\nall_categories = []\nfor filename in findFiles('/kaggle/input/charrnn/data/names/*.txt'):\n    category = os.path.splitext(os.path.basename(filename))[0]\n    all_categories.append(category)\n    lines = readLines(filename)\n    category_lines[category] = lines\n\nn_categories = len(all_categories)\n\nif n_categories == 0:\n    raise RuntimeError('Data not found. Make sure that you downloaded data '\n        'from https://download.pytorch.org/tutorial/data.zip and extract it to '\n        'the current directory.')\n\nprint('# categories:', n_categories, all_categories)\nprint(unicodeToAscii(\"O'Néàl\"))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-23T22:20:08.010213Z","iopub.execute_input":"2022-02-23T22:20:08.011014Z","iopub.status.idle":"2022-02-23T22:20:08.176471Z","shell.execute_reply.started":"2022-02-23T22:20:08.010911Z","shell.execute_reply":"2022-02-23T22:20:08.175706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass RNN(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(RNN, self).__init__()\n        self.hidden_size = hidden_size\n\n        self.i2h = nn.Linear(n_categories + input_size + hidden_size, hidden_size)\n        self.i2o = nn.Linear(n_categories + input_size + hidden_size, output_size)\n        self.o2o = nn.Linear(hidden_size + output_size, output_size)\n        self.dropout = nn.Dropout(0.1)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, category, input, hidden):\n        input_combined = torch.cat((category, input, hidden), 1)\n        hidden = self.i2h(input_combined)\n        output = self.i2o(input_combined)\n        output_combined = torch.cat((hidden, output), 1)\n        output = self.o2o(output_combined)\n        output = self.dropout(output)\n        output = self.softmax(output)\n        return output, hidden\n\n    def initHidden(self):\n        return torch.zeros(1, self.hidden_size)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T22:20:59.652748Z","iopub.execute_input":"2022-02-23T22:20:59.653567Z","iopub.status.idle":"2022-02-23T22:21:00.935905Z","shell.execute_reply.started":"2022-02-23T22:20:59.65352Z","shell.execute_reply":"2022-02-23T22:21:00.93521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\n\n# Random item from a list\ndef randomChoice(l):\n    return l[random.randint(0, len(l) - 1)]\n\n# Get a random category and random line from that category\ndef randomTrainingPair():\n    category = randomChoice(all_categories)\n    line = randomChoice(category_lines[category])\n    return category, line","metadata":{"execution":{"iopub.status.busy":"2022-02-23T22:21:57.829452Z","iopub.execute_input":"2022-02-23T22:21:57.829703Z","iopub.status.idle":"2022-02-23T22:21:57.834506Z","shell.execute_reply.started":"2022-02-23T22:21:57.829673Z","shell.execute_reply":"2022-02-23T22:21:57.833823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# One-hot vector for category\ndef categoryTensor(category):\n    li = all_categories.index(category)\n    tensor = torch.zeros(1, n_categories)\n    tensor[0][li] = 1\n    return tensor\n\n# One-hot matrix of first to last letters (not including EOS) for input\ndef inputTensor(line):\n    tensor = torch.zeros(len(line), 1, n_letters)\n    for li in range(len(line)):\n        letter = line[li]\n        tensor[li][0][all_letters.find(letter)] = 1\n    return tensor\n\n# LongTensor of second letter to end (EOS) for target\ndef targetTensor(line):\n    letter_indexes = [all_letters.find(line[li]) for li in range(1, len(line))]\n    letter_indexes.append(n_letters - 1) # EOS\n    return torch.LongTensor(letter_indexes)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T22:22:12.896015Z","iopub.execute_input":"2022-02-23T22:22:12.896276Z","iopub.status.idle":"2022-02-23T22:22:12.903392Z","shell.execute_reply.started":"2022-02-23T22:22:12.896245Z","shell.execute_reply":"2022-02-23T22:22:12.902665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make category, input, and target tensors from a random category, line pair\ndef randomTrainingExample():\n    category, line = randomTrainingPair()\n    category_tensor = categoryTensor(category)\n    input_line_tensor = inputTensor(line)\n    target_line_tensor = targetTensor(line)\n    return category_tensor, input_line_tensor, target_line_tensor","metadata":{"execution":{"iopub.status.busy":"2022-02-23T22:22:35.868923Z","iopub.execute_input":"2022-02-23T22:22:35.869181Z","iopub.status.idle":"2022-02-23T22:22:35.873726Z","shell.execute_reply.started":"2022-02-23T22:22:35.86915Z","shell.execute_reply":"2022-02-23T22:22:35.873054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.NLLLoss()\n\nlearning_rate = 0.0005\n\ndef train(category_tensor, input_line_tensor, target_line_tensor):\n    target_line_tensor.unsqueeze_(-1)\n    hidden = rnn.initHidden()\n\n    rnn.zero_grad()\n\n    loss = 0\n\n    for i in range(input_line_tensor.size(0)):\n        output, hidden = rnn(category_tensor, input_line_tensor[i], hidden)\n        l = criterion(output, target_line_tensor[i])\n        loss += l\n\n    loss.backward()\n\n    for p in rnn.parameters():\n        p.data.add_(p.grad.data, alpha=-learning_rate)\n\n    return output, loss.item() / input_line_tensor.size(0)\n\nimport time\nimport math\n\ndef timeSince(since):\n    now = time.time()\n    s = now - since\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\nrnn = RNN(n_letters, 128, n_letters)\n\nn_iters = 100000\nprint_every = 5000\nplot_every = 500\nall_losses = []\ntotal_loss = 0 # Reset every plot_every iters\n\nstart = time.time()\n\nfor iter in range(1, n_iters + 1):\n    output, loss = train(*randomTrainingExample())\n    total_loss += loss\n\n    if iter % print_every == 0:\n        print('%s (%d %d%%) %.4f' % (timeSince(start), iter, iter / n_iters * 100, loss))\n\n    if iter % plot_every == 0:\n        all_losses.append(total_loss / plot_every)\n        total_loss = 0","metadata":{"execution":{"iopub.status.busy":"2022-02-23T22:23:29.712633Z","iopub.execute_input":"2022-02-23T22:23:29.713284Z","iopub.status.idle":"2022-02-23T22:27:37.42967Z","shell.execute_reply.started":"2022-02-23T22:23:29.713245Z","shell.execute_reply":"2022-02-23T22:27:37.428914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure()\nplt.plot(all_losses)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T22:27:44.933747Z","iopub.execute_input":"2022-02-23T22:27:44.934021Z","iopub.status.idle":"2022-02-23T22:27:45.159699Z","shell.execute_reply.started":"2022-02-23T22:27:44.933989Z","shell.execute_reply":"2022-02-23T22:27:45.159017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_length = 20\n\n# Sample from a category and starting letter\ndef sample(category, start_letter='A'):\n    with torch.no_grad():  # no need to track history in sampling\n        category_tensor = categoryTensor(category)\n        input = inputTensor(start_letter)\n        hidden = rnn.initHidden()\n\n        output_name = start_letter\n\n        for i in range(max_length):\n            output, hidden = rnn(category_tensor, input[0], hidden)\n            topv, topi = output.topk(1)\n            topi = topi[0][0]\n            if topi == n_letters - 1:\n                break\n            else:\n                letter = all_letters[topi]\n                output_name += letter\n            input = inputTensor(letter)\n\n        return output_name\n\n# Get multiple samples from one category and multiple starting letters\ndef samples(category, start_letters='ABC'):\n    for start_letter in start_letters:\n        print(sample(category, start_letter))\n\nsamples('Russian', 'RUS')\n\nsamples('German', 'GER')\n\nsamples('Spanish', 'SPA')\n\nsamples('Chinese', 'CHI')\n\nsamples('Italian', 'ITA')","metadata":{"execution":{"iopub.status.busy":"2022-02-23T22:29:46.899996Z","iopub.execute_input":"2022-02-23T22:29:46.900255Z","iopub.status.idle":"2022-02-23T22:29:46.933824Z","shell.execute_reply.started":"2022-02-23T22:29:46.900227Z","shell.execute_reply":"2022-02-23T22:29:46.933037Z"},"trusted":true},"execution_count":null,"outputs":[]}]}