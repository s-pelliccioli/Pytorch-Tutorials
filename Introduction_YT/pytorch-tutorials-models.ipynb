{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.functional as F","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-03T21:02:25.353152Z","iopub.execute_input":"2022-02-03T21:02:25.353493Z","iopub.status.idle":"2022-02-03T21:02:25.357616Z","shell.execute_reply.started":"2022-02-03T21:02:25.35346Z","shell.execute_reply":"2022-02-03T21:02:25.356892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TinyModel(torch.nn.Module):\n\n    def __init__(self):\n        super(TinyModel, self).__init__()\n\n        self.linear1 = torch.nn.Linear(100, 200)\n        self.activation = torch.nn.ReLU()\n        self.linear2 = torch.nn.Linear(200, 10)\n        self.softmax = torch.nn.Softmax()\n\n    def forward(self, x):\n        x = self.linear1(x)\n        x = self.activation(x)\n        x = self.linear2(x)\n        x = self.softmax(x)\n        return x\n\ntinymodel = TinyModel()\n\nprint('The model:')\nprint(tinymodel)\n\nprint('\\n\\nJust one layer:')\nprint(tinymodel.linear2)\n\nprint('\\n\\nModel params:')\nfor param in tinymodel.parameters():\n    print(param)\n\nprint('\\n\\nLayer params:')\nfor param in tinymodel.linear2.parameters():\n    print(param)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:51:59.508988Z","iopub.execute_input":"2022-02-03T20:51:59.509288Z","iopub.status.idle":"2022-02-03T20:51:59.617846Z","shell.execute_reply.started":"2022-02-03T20:51:59.509253Z","shell.execute_reply":"2022-02-03T20:51:59.616937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lin = torch.nn.Linear(3, 2)\nx = torch.rand(1, 3)\nprint('Input:')\nprint(x)\n\nprint('\\n\\nWeight and Bias parameters:')\nfor param in lin.parameters():\n    print(param)\n\ny = lin(x)\nprint('\\n\\nOutput:')\nprint(y)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:57:37.562183Z","iopub.execute_input":"2022-02-03T20:57:37.562509Z","iopub.status.idle":"2022-02-03T20:57:37.592559Z","shell.execute_reply.started":"2022-02-03T20:57:37.562479Z","shell.execute_reply":"2022-02-03T20:57:37.591612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LeNet(torch.nn.Module):\n\n    def __init__(self):\n        super(LeNet, self).__init__()\n        # 1 input image channel (black & white), 6 output channels, 5x5 square convolution\n        # kernel\n        self.conv1 = torch.nn.Conv2d(1, 6, 5)\n        self.conv2 = torch.nn.Conv2d(6, 16, 3)\n        # an affine operation: y = Wx + b\n        self.fc1 = torch.nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n        self.fc2 = torch.nn.Linear(120, 84)\n        self.fc3 = torch.nn.Linear(84, 10)\n\n    def forward(self, x):\n        # Max pooling over a (2, 2) window\n        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n        # If the size is a square you can only specify a single number\n        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n        x = x.view(-1, self.num_flat_features(x))\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n    def num_flat_features(self, x):\n        size = x.size()[1:]  # all dimensions except the batch dimension\n        num_features = 1\n        for s in size:\n            num_features *= s\n        return num_features","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:08:55.883139Z","iopub.execute_input":"2022-02-03T21:08:55.883475Z","iopub.status.idle":"2022-02-03T21:08:55.894668Z","shell.execute_reply.started":"2022-02-03T21:08:55.883443Z","shell.execute_reply":"2022-02-03T21:08:55.8938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LSTMTagger(torch.nn.Module):\n\n    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n        super(LSTMTagger, self).__init__()\n        self.hidden_dim = hidden_dim\n\n        self.word_embeddings = torch.nn.Embedding(vocab_size, embedding_dim)\n\n        # The LSTM takes word embeddings as inputs, and outputs hidden states\n        # with dimensionality hidden_dim.\n        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim)\n\n        # The linear layer that maps from hidden state space to tag space\n        self.hidden2tag = torch.nn.Linear(hidden_dim, tagset_size)\n\n    def forward(self, sentence):\n        embeds = self.word_embeddings(sentence)\n        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n        tag_scores = F.log_softmax(tag_space, dim=1)\n        return tag_scores","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:16:29.56706Z","iopub.execute_input":"2022-02-03T21:16:29.567938Z","iopub.status.idle":"2022-02-03T21:16:29.576042Z","shell.execute_reply.started":"2022-02-03T21:16:29.567885Z","shell.execute_reply":"2022-02-03T21:16:29.575384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_tensor = torch.rand(1, 6, 6)\nprint(my_tensor)\n\nmaxpool_layer = torch.nn.MaxPool2d(3)\nprint(maxpool_layer(my_tensor))\n\nmy_tensor = torch.rand(1, 4, 4) * 20 + 5\nprint(my_tensor)\n\nprint(my_tensor.mean())\n\nnorm_layer = torch.nn.BatchNorm1d(4)\nnormed_tensor = norm_layer(my_tensor)\nprint(normed_tensor)\n\nprint(normed_tensor.mean())\n\nmy_tensor = torch.rand(1, 4, 4)\n\ndropout = torch.nn.Dropout(p=0.4)\nprint(dropout(my_tensor))\nprint(dropout(my_tensor))","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:24:14.289834Z","iopub.execute_input":"2022-02-03T21:24:14.290315Z","iopub.status.idle":"2022-02-03T21:24:14.331883Z","shell.execute_reply.started":"2022-02-03T21:24:14.290268Z","shell.execute_reply":"2022-02-03T21:24:14.331205Z"},"trusted":true},"execution_count":null,"outputs":[]}]}