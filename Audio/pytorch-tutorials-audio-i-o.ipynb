{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchaudio\n\nprint(torch.__version__)\nprint(torchaudio.__version__)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-15T21:15:00.274493Z","iopub.execute_input":"2022-02-15T21:15:00.275082Z","iopub.status.idle":"2022-02-15T21:15:00.47643Z","shell.execute_reply.started":"2022-02-15T21:15:00.275014Z","shell.execute_reply":"2022-02-15T21:15:00.475645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#@title Prepare data and utility functions. {display-mode: \"form\"}\n#@markdown\n#@markdown You do not need to look into this cell.\n#@markdown Just execute once and you are good to go.\n#@markdown\n#@markdown In this tutorial, we will use a speech data from [VOiCES dataset](https://iqtlabs.github.io/voices/), which is licensed under Creative Commos BY 4.0.\n\n\nimport io\nimport os\nimport requests\nimport tarfile\n\nimport boto3\nfrom botocore import UNSIGNED\nfrom botocore.config import Config\nimport matplotlib.pyplot as plt\nfrom IPython.display import Audio, display\n\n\n_SAMPLE_DIR = \"_sample_data\"\nSAMPLE_WAV_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/steam-train-whistle-daniel_simon.wav\"\nSAMPLE_WAV_PATH = os.path.join(_SAMPLE_DIR, \"steam.wav\")\n\nSAMPLE_MP3_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/steam-train-whistle-daniel_simon.mp3\"\nSAMPLE_MP3_PATH = os.path.join(_SAMPLE_DIR, \"steam.mp3\")\n\nSAMPLE_GSM_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/steam-train-whistle-daniel_simon.gsm\"\nSAMPLE_GSM_PATH = os.path.join(_SAMPLE_DIR, \"steam.gsm\")\n\nSAMPLE_WAV_SPEECH_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/source-16k/train/sp0307/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav\"\nSAMPLE_WAV_SPEECH_PATH = os.path.join(_SAMPLE_DIR, \"speech.wav\")\n\nSAMPLE_TAR_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit.tar.gz\"\nSAMPLE_TAR_PATH = os.path.join(_SAMPLE_DIR, \"sample.tar.gz\")\nSAMPLE_TAR_ITEM = \"VOiCES_devkit/source-16k/train/sp0307/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav\"\n\nS3_BUCKET = \"pytorch-tutorial-assets\"\nS3_KEY = \"VOiCES_devkit/source-16k/train/sp0307/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav\"\n\n\ndef _fetch_data():\n    os.makedirs(_SAMPLE_DIR, exist_ok=True)\n    uri = [\n    (SAMPLE_WAV_URL, SAMPLE_WAV_PATH),\n    (SAMPLE_MP3_URL, SAMPLE_MP3_PATH),\n    (SAMPLE_GSM_URL, SAMPLE_GSM_PATH),\n    (SAMPLE_WAV_SPEECH_URL, SAMPLE_WAV_SPEECH_PATH),\n    (SAMPLE_TAR_URL, SAMPLE_TAR_PATH),\n    ]\n    for url, path in uri:\n        with open(path, 'wb') as file_:\n            file_.write(requests.get(url).content)\n\n_fetch_data()\n\ndef print_stats(waveform, sample_rate=None, src=None):\n    if src:\n        print(\"-\" * 10)\n        print(\"Source:\", src)\n        print(\"-\" * 10)\n    if sample_rate:\n        print(\"Sample Rate:\", sample_rate)\n    print(\"Shape:\", tuple(waveform.shape))\n    print(\"Dtype:\", waveform.dtype)\n    print(f\" - Max:     {waveform.max().item():6.3f}\")\n    print(f\" - Min:     {waveform.min().item():6.3f}\")\n    print(f\" - Mean:    {waveform.mean().item():6.3f}\")\n    print(f\" - Std Dev: {waveform.std().item():6.3f}\")\n    print()\n    print(waveform)\n    print()\n\ndef plot_waveform(waveform, sample_rate, title=\"Waveform\", xlim=None, ylim=None):\n    waveform = waveform.numpy()\n\n    num_channels, num_frames = waveform.shape\n    time_axis = torch.arange(0, num_frames) / sample_rate\n\n    figure, axes = plt.subplots(num_channels, 1)\n    if num_channels == 1:\n        axes = [axes]\n    for c in range(num_channels):\n        axes[c].plot(time_axis, waveform[c], linewidth=1)\n        axes[c].grid(True)\n        if num_channels > 1:\n            axes[c].set_ylabel(f'Channel {c+1}')\n        if xlim:\n            axes[c].set_xlim(xlim)\n        if ylim:\n            axes[c].set_ylim(ylim)\n        figure.suptitle(title)\n        plt.show(block=False)\n\ndef plot_specgram(waveform, sample_rate, title=\"Spectrogram\", xlim=None):\n    waveform = waveform.numpy()\n\n    num_channels, num_frames = waveform.shape\n    time_axis = torch.arange(0, num_frames) / sample_rate\n\n    figure, axes = plt.subplots(num_channels, 1)\n    if num_channels == 1:\n        axes = [axes]\n    for c in range(num_channels):\n        axes[c].specgram(waveform[c], Fs=sample_rate)\n        if num_channels > 1:\n            axes[c].set_ylabel(f'Channel {c+1}')\n        if xlim:\n            axes[c].set_xlim(xlim)\n    figure.suptitle(title)\n    plt.show(block=False)\n\ndef play_audio(waveform, sample_rate):\n    waveform = waveform.numpy()\n\n    num_channels, num_frames = waveform.shape\n    if num_channels == 1:\n        display(Audio(waveform[0], rate=sample_rate))\n    elif num_channels == 2:\n        display(Audio((waveform[0], waveform[1]), rate=sample_rate))\n    else:\n        raise ValueError(\"Waveform with more than 2 channels are not supported.\")\n\ndef _get_sample(path, resample=None):\n    effects = [[\"remix\", \"1\"]]\n    if resample:\n        effects.extend([\n          [\"lowpass\", f\"{resample // 2}\"],\n          [\"rate\", f'{resample}'],\n        ])\n    return torchaudio.sox_effects.apply_effects_file(path, effects=effects)\n\ndef get_sample(*, resample=None):\n    return _get_sample(SAMPLE_WAV_PATH, resample=resample)\n\ndef inspect_file(path):\n    print(\"-\" * 10)\n    print(\"Source:\", path)\n    print(\"-\" * 10)\n    print(f\" - File size: {os.path.getsize(path)} bytes\")\n    print(f\" - {torchaudio.info(path)}\")","metadata":{"execution":{"iopub.status.busy":"2022-02-15T21:22:10.881458Z","iopub.execute_input":"2022-02-15T21:22:10.881692Z","iopub.status.idle":"2022-02-15T21:22:11.776587Z","shell.execute_reply.started":"2022-02-15T21:22:10.881665Z","shell.execute_reply":"2022-02-15T21:22:11.77545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metadata = torchaudio.info(SAMPLE_WAV_PATH)\nprint(metadata)\nmetadata = torchaudio.info(SAMPLE_MP3_PATH)\nprint(metadata)\nmetadata = torchaudio.info(SAMPLE_GSM_PATH)\nprint(metadata)\n\nprint(\"Source:\", SAMPLE_WAV_URL)\nwith requests.get(SAMPLE_WAV_URL, stream=True) as response:\n    metadata = torchaudio.info(response.raw)\nprint(metadata)\n\nprint(\"Source:\", SAMPLE_MP3_URL)\nwith requests.get(SAMPLE_MP3_URL, stream=True) as response:\n    metadata = torchaudio.info(response.raw, format=\"mp3\")\n    print(f\"Fetched {response.raw.tell()} bytes.\")\nprint(metadata)","metadata":{"execution":{"iopub.status.busy":"2022-02-15T21:25:33.176271Z","iopub.execute_input":"2022-02-15T21:25:33.176912Z","iopub.status.idle":"2022-02-15T21:25:33.482077Z","shell.execute_reply.started":"2022-02-15T21:25:33.176876Z","shell.execute_reply":"2022-02-15T21:25:33.481251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"waveform, sample_rate = torchaudio.load(SAMPLE_WAV_SPEECH_PATH)\n\nprint_stats(waveform, sample_rate=sample_rate)\nplot_waveform(waveform, sample_rate)\nplot_specgram(waveform, sample_rate)\nplay_audio(waveform, sample_rate)","metadata":{"execution":{"iopub.status.busy":"2022-02-15T21:27:09.507983Z","iopub.execute_input":"2022-02-15T21:27:09.508255Z","iopub.status.idle":"2022-02-15T21:27:10.529824Z","shell.execute_reply.started":"2022-02-15T21:27:09.508228Z","shell.execute_reply":"2022-02-15T21:27:10.528623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load audio data as HTTP request\nwith requests.get(SAMPLE_WAV_SPEECH_URL, stream=True) as response:\n    waveform, sample_rate = torchaudio.load(response.raw)\nplot_specgram(waveform, sample_rate, title=\"HTTP datasource\")\n\n# Load audio from tar file\nwith tarfile.open(SAMPLE_TAR_PATH, mode='r') as tarfile_:\n    fileobj = tarfile_.extractfile(SAMPLE_TAR_ITEM)\n    waveform, sample_rate = torchaudio.load(fileobj)\nplot_specgram(waveform, sample_rate, title=\"TAR file\")\n\n# Load audio from S3\nclient = boto3.client('s3', config=Config(signature_version=UNSIGNED))\nresponse = client.get_object(Bucket=S3_BUCKET, Key=S3_KEY)\nwaveform, sample_rate = torchaudio.load(response['Body'])\nplot_specgram(waveform, sample_rate, title=\"From S3\")","metadata":{"execution":{"iopub.status.busy":"2022-02-15T21:28:22.202382Z","iopub.execute_input":"2022-02-15T21:28:22.202678Z","iopub.status.idle":"2022-02-15T21:28:23.555315Z","shell.execute_reply.started":"2022-02-15T21:28:22.202648Z","shell.execute_reply":"2022-02-15T21:28:23.554274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Illustration of two different decoding methods.\n# The first one will fetch all the data and decode them, while\n# the second one will stop fetching data once it completes decoding.\n# The resulting waveforms are identical.\n\nframe_offset, num_frames = 16000, 16000  # Fetch and decode the 1 - 2 seconds\n\nprint(\"Fetching all the data...\")\nwith requests.get(SAMPLE_WAV_SPEECH_URL, stream=True) as response:\n    waveform1, sample_rate1 = torchaudio.load(response.raw)\n    waveform1 = waveform1[:, frame_offset:frame_offset+num_frames]\n    print(f\" - Fetched {response.raw.tell()} bytes\")\n\nprint(\"Fetching until the requested frames are available...\")\nwith requests.get(SAMPLE_WAV_SPEECH_URL, stream=True) as response:\n    waveform2, sample_rate2 = torchaudio.load(\n        response.raw, frame_offset=frame_offset, num_frames=num_frames)\n    print(f\" - Fetched {response.raw.tell()} bytes\")\n\nprint(\"Checking the resulting waveform ... \", end=\"\")\nassert (waveform1 == waveform2).all()\nprint(\"matched!\")","metadata":{"execution":{"iopub.status.busy":"2022-02-15T21:29:46.969794Z","iopub.execute_input":"2022-02-15T21:29:46.970063Z","iopub.status.idle":"2022-02-15T21:29:47.790714Z","shell.execute_reply.started":"2022-02-15T21:29:46.970036Z","shell.execute_reply":"2022-02-15T21:29:47.789213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"waveform, sample_rate = get_sample()\nprint_stats(waveform, sample_rate=sample_rate)\n\n# Save without any encoding option.\n# The function will pick up the encoding which\n# the provided data fit\npath = \"save_example_default.wav\"\ntorchaudio.save(path, waveform, sample_rate)\ninspect_file(path)\n\n# Save as 16-bit signed integer Linear PCM\n# The resulting file occupies half the storage but loses precision\npath = \"save_example_PCM_S16.wav\"\ntorchaudio.save(\n    path, waveform, sample_rate,\n    encoding=\"PCM_S\", bits_per_sample=16)\ninspect_file(path)","metadata":{"execution":{"iopub.status.busy":"2022-02-15T21:33:34.005897Z","iopub.execute_input":"2022-02-15T21:33:34.006724Z","iopub.status.idle":"2022-02-15T21:33:34.031604Z","shell.execute_reply.started":"2022-02-15T21:33:34.006692Z","shell.execute_reply":"2022-02-15T21:33:34.030387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"waveform, sample_rate = get_sample(resample=8000)\n\nformats = [\n  \"mp3\",\n  \"flac\",\n  \"vorbis\",\n  \"sph\",\n  \"amb\",\n  \"amr-nb\",\n  \"gsm\",\n]\n\nfor format in formats:\n    path = f\"save_example.{format}\"\n    torchaudio.save(path, waveform, sample_rate, format=format)\n    inspect_file(path)","metadata":{"execution":{"iopub.status.busy":"2022-02-15T21:34:23.143459Z","iopub.execute_input":"2022-02-15T21:34:23.143765Z","iopub.status.idle":"2022-02-15T21:34:23.234744Z","shell.execute_reply.started":"2022-02-15T21:34:23.143733Z","shell.execute_reply":"2022-02-15T21:34:23.233813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"waveform, sample_rate = get_sample()\n\n# Saving to bytes buffer\nbuffer_ = io.BytesIO()\ntorchaudio.save(buffer_, waveform, sample_rate, format=\"wav\")\n\nbuffer_.seek(0)\nprint(buffer_.read(16))","metadata":{"execution":{"iopub.status.busy":"2022-02-15T21:35:07.870608Z","iopub.execute_input":"2022-02-15T21:35:07.870869Z","iopub.status.idle":"2022-02-15T21:35:07.882845Z","shell.execute_reply.started":"2022-02-15T21:35:07.870831Z","shell.execute_reply":"2022-02-15T21:35:07.881974Z"},"trusted":true},"execution_count":null,"outputs":[]}]}