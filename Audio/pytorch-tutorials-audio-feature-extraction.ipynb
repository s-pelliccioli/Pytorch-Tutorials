{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchaudio\nimport torchaudio.functional as F\nimport torchaudio.transforms as T\n\nprint(torch.__version__)\nprint(torchaudio.__version__)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-19T17:18:10.464951Z","iopub.execute_input":"2022-02-19T17:18:10.465669Z","iopub.status.idle":"2022-02-19T17:18:11.82292Z","shell.execute_reply.started":"2022-02-19T17:18:10.465513Z","shell.execute_reply":"2022-02-19T17:18:11.82191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport requests\n\nimport librosa\nimport matplotlib.pyplot as plt\nfrom IPython.display import Audio, display\n\n\n_SAMPLE_DIR = \"_sample_data\"\n\nSAMPLE_WAV_SPEECH_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/source-16k/train/sp0307/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav\"\nSAMPLE_WAV_SPEECH_PATH = os.path.join(_SAMPLE_DIR, \"speech.wav\")\n\nos.makedirs(_SAMPLE_DIR, exist_ok=True)\n\n\ndef _fetch_data():\n    uri = [\n        (SAMPLE_WAV_SPEECH_URL, SAMPLE_WAV_SPEECH_PATH),\n    ]\n    for url, path in uri:\n        with open(path, 'wb') as file_:\n            file_.write(requests.get(url).content)\n\n_fetch_data()\n\ndef _get_sample(path, resample=None):\n    effects = [\n        [\"remix\", \"1\"]\n    ]\n    if resample:\n        effects.extend([\n          [\"lowpass\", f\"{resample // 2}\"],\n          [\"rate\", f'{resample}'],\n        ])\n    return torchaudio.sox_effects.apply_effects_file(path, effects=effects)\n\ndef get_speech_sample(*, resample=None):\n    return _get_sample(SAMPLE_WAV_SPEECH_PATH, resample=resample)\n\ndef print_stats(waveform, sample_rate=None, src=None):\n    if src:\n        print(\"-\" * 10)\n        print(\"Source:\", src)\n        print(\"-\" * 10)\n    if sample_rate:\n        print(\"Sample Rate:\", sample_rate)\n    print(\"Shape:\", tuple(waveform.shape))\n    print(\"Dtype:\", waveform.dtype)\n    print(f\" - Max:     {waveform.max().item():6.3f}\")\n    print(f\" - Min:     {waveform.min().item():6.3f}\")\n    print(f\" - Mean:    {waveform.mean().item():6.3f}\")\n    print(f\" - Std Dev: {waveform.std().item():6.3f}\")\n    print()\n    print(waveform)\n    print()\n\ndef plot_spectrogram(spec, title=None, ylabel='freq_bin', aspect='auto', xmax=None):\n    fig, axs = plt.subplots(1, 1)\n    axs.set_title(title or 'Spectrogram (db)')\n    axs.set_ylabel(ylabel)\n    axs.set_xlabel('frame')\n    im = axs.imshow(librosa.power_to_db(spec), origin='lower', aspect=aspect)\n    if xmax:\n        axs.set_xlim((0, xmax))\n    fig.colorbar(im, ax=axs)\n    plt.show(block=False)\n\ndef plot_waveform(waveform, sample_rate, title=\"Waveform\", xlim=None, ylim=None):\n    waveform = waveform.numpy()\n\n    num_channels, num_frames = waveform.shape\n    time_axis = torch.arange(0, num_frames) / sample_rate\n\n    figure, axes = plt.subplots(num_channels, 1)\n    if num_channels == 1:\n        axes = [axes]\n    for c in range(num_channels):\n        axes[c].plot(time_axis, waveform[c], linewidth=1)\n        axes[c].grid(True)\n        if num_channels > 1:\n            axes[c].set_ylabel(f'Channel {c+1}')\n        if xlim:\n            axes[c].set_xlim(xlim)\n        if ylim:\n            axes[c].set_ylim(ylim)\n    figure.suptitle(title)\n    plt.show(block=False)\n\ndef play_audio(waveform, sample_rate):\n    waveform = waveform.numpy()\n\n    num_channels, num_frames = waveform.shape\n    if num_channels == 1:\n        display(Audio(waveform[0], rate=sample_rate))\n    elif num_channels == 2:\n        display(Audio((waveform[0], waveform[1]), rate=sample_rate))\n    else:\n        raise ValueError(\"Waveform with more than 2 channels are not supported.\")\n\ndef plot_mel_fbank(fbank, title=None):\n    fig, axs = plt.subplots(1, 1)\n    axs.set_title(title or 'Filter bank')\n    axs.imshow(fbank, aspect='auto')\n    axs.set_ylabel('frequency bin')\n    axs.set_xlabel('mel bin')\n    plt.show(block=False)\n\ndef plot_pitch(waveform, sample_rate, pitch):\n    figure, axis = plt.subplots(1, 1)\n    axis.set_title(\"Pitch Feature\")\n    axis.grid(True)\n\n    end_time = waveform.shape[1] / sample_rate\n    time_axis = torch.linspace(0, end_time,  waveform.shape[1])\n    axis.plot(time_axis, waveform[0], linewidth=1, color='gray', alpha=0.3)\n\n    axis2 = axis.twinx()\n    time_axis = torch.linspace(0, end_time, pitch.shape[1])\n    ln2 = axis2.plot(\n          time_axis, pitch[0], linewidth=2, label='Pitch', color='green')\n\n    axis2.legend(loc=0)\n    plt.show(block=False)\n\ndef plot_kaldi_pitch(waveform, sample_rate, pitch, nfcc):\n    figure, axis = plt.subplots(1, 1)\n    axis.set_title(\"Kaldi Pitch Feature\")\n    axis.grid(True)\n\n    end_time = waveform.shape[1] / sample_rate\n    time_axis = torch.linspace(0, end_time,  waveform.shape[1])\n    axis.plot(time_axis, waveform[0], linewidth=1, color='gray', alpha=0.3)\n\n    time_axis = torch.linspace(0, end_time, pitch.shape[1])\n    ln1 = axis.plot(time_axis, pitch[0], linewidth=2, label='Pitch', color='green')\n    axis.set_ylim((-1.3, 1.3))\n\n    axis2 = axis.twinx()\n    time_axis = torch.linspace(0, end_time, nfcc.shape[1])\n    ln2 = axis2.plot(\n          time_axis, nfcc[0], linewidth=2, label='NFCC', color='blue', linestyle='--')\n\n    lns = ln1 + ln2\n    labels = [l.get_label() for l in lns]\n    axis.legend(lns, labels, loc=0)\n    plt.show(block=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T17:23:47.642828Z","iopub.execute_input":"2022-02-19T17:23:47.643169Z","iopub.status.idle":"2022-02-19T17:23:50.572224Z","shell.execute_reply.started":"2022-02-19T17:23:47.643139Z","shell.execute_reply":"2022-02-19T17:23:50.571371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"waveform, sample_rate = get_speech_sample()\n\nn_fft = 1024\nwin_length = None\nhop_length = 512\n\n# define transformation\nspectrogram = T.Spectrogram(\n    n_fft=n_fft,\n    win_length=win_length,\n    hop_length=hop_length,\n    center=True,\n    pad_mode=\"reflect\",\n    power=2.0,\n)\n# Perform transformation\nspec = spectrogram(waveform)\n\nprint_stats(spec)\nplot_spectrogram(spec[0], title='torchaudio')","metadata":{"execution":{"iopub.status.busy":"2022-02-19T17:24:19.193838Z","iopub.execute_input":"2022-02-19T17:24:19.194174Z","iopub.status.idle":"2022-02-19T17:24:19.73333Z","shell.execute_reply.started":"2022-02-19T17:24:19.194137Z","shell.execute_reply":"2022-02-19T17:24:19.721821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.random.manual_seed(0)\nwaveform, sample_rate = get_speech_sample()\nplot_waveform(waveform, sample_rate, title=\"Original\")\nplay_audio(waveform, sample_rate)\n\nn_fft = 1024\nwin_length = None\nhop_length = 512\n\nspec = T.Spectrogram(\n    n_fft=n_fft,\n    win_length=win_length,\n    hop_length=hop_length,\n)(waveform)\n\ngriffin_lim = T.GriffinLim(\n    n_fft=n_fft,\n    win_length=win_length,\n    hop_length=hop_length,\n)\nwaveform = griffin_lim(spec)\n\nplot_waveform(waveform, sample_rate, title=\"Reconstructed\")\nplay_audio(waveform, sample_rate)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T17:24:53.107907Z","iopub.execute_input":"2022-02-19T17:24:53.108219Z","iopub.status.idle":"2022-02-19T17:24:54.722261Z","shell.execute_reply.started":"2022-02-19T17:24:53.108187Z","shell.execute_reply":"2022-02-19T17:24:54.72147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_fft = 256\nn_mels = 64\nsample_rate = 6000\n\nmel_filters = F.create_fb_matrix(\n    int(n_fft // 2 + 1),\n    n_mels=n_mels,\n    f_min=0.,\n    f_max=sample_rate/2.,\n    sample_rate=sample_rate,\n    norm='slaney'\n)\nplot_mel_fbank(mel_filters, \"Mel Filter Bank - torchaudio\")","metadata":{"execution":{"iopub.status.busy":"2022-02-19T17:25:36.680052Z","iopub.execute_input":"2022-02-19T17:25:36.680853Z","iopub.status.idle":"2022-02-19T17:25:36.90131Z","shell.execute_reply.started":"2022-02-19T17:25:36.680815Z","shell.execute_reply":"2022-02-19T17:25:36.900647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mel_filters_librosa = librosa.filters.mel(\n    sr=sample_rate,\n    n_fft=n_fft,\n    n_mels=n_mels,\n    fmin=0.,\n    fmax=sample_rate/2.,\n    norm='slaney',\n    htk=True,\n).T\n\nplot_mel_fbank(mel_filters_librosa, \"Mel Filter Bank - librosa\")\n\nmse = torch.square(mel_filters - mel_filters_librosa).mean().item()\nprint('Mean Square Difference: ', mse)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T17:27:35.085339Z","iopub.execute_input":"2022-02-19T17:27:35.08641Z","iopub.status.idle":"2022-02-19T17:27:35.275807Z","shell.execute_reply.started":"2022-02-19T17:27:35.086364Z","shell.execute_reply":"2022-02-19T17:27:35.274925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"waveform, sample_rate = get_speech_sample()\n\nn_fft = 1024\nwin_length = None\nhop_length = 512\nn_mels = 128\n\nmel_spectrogram = T.MelSpectrogram(\n    sample_rate=sample_rate,\n    n_fft=n_fft,\n    win_length=win_length,\n    hop_length=hop_length,\n    center=True,\n    pad_mode=\"reflect\",\n    power=2.0,\n    norm='slaney',\n    onesided=True,\n    n_mels=n_mels,\n    mel_scale=\"htk\",\n)\n\nmelspec = mel_spectrogram(waveform)\nplot_spectrogram(\n    melspec[0], title=\"MelSpectrogram - torchaudio\", ylabel='mel freq')","metadata":{"execution":{"iopub.status.busy":"2022-02-19T17:29:11.825107Z","iopub.execute_input":"2022-02-19T17:29:11.82605Z","iopub.status.idle":"2022-02-19T17:29:12.131942Z","shell.execute_reply.started":"2022-02-19T17:29:11.825997Z","shell.execute_reply":"2022-02-19T17:29:12.131062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"melspec_librosa = librosa.feature.melspectrogram(\n    y=waveform.numpy()[0],\n    sr=sample_rate,\n    n_fft=n_fft,\n    hop_length=hop_length,\n    win_length=win_length,\n    center=True,\n    pad_mode=\"reflect\",\n    power=2.0,\n    n_mels=n_mels,\n    norm='slaney',\n    htk=True,\n)\nplot_spectrogram(\n    melspec_librosa, title=\"MelSpectrogram - librosa\", ylabel='mel freq')\n\nmse = torch.square(melspec - melspec_librosa).mean().item()\nprint('Mean Square Difference: ', mse)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T17:30:36.923457Z","iopub.execute_input":"2022-02-19T17:30:36.923939Z","iopub.status.idle":"2022-02-19T17:30:37.253899Z","shell.execute_reply.started":"2022-02-19T17:30:36.923907Z","shell.execute_reply":"2022-02-19T17:30:37.252846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"waveform, sample_rate = get_speech_sample()\n\nn_fft = 2048\nwin_length = None\nhop_length = 512\nn_mels = 256\nn_mfcc = 256\n\nmfcc_transform = T.MFCC(\n    sample_rate=sample_rate,\n    n_mfcc=n_mfcc,\n    melkwargs={\n      'n_fft': n_fft,\n      'n_mels': n_mels,\n      'hop_length': hop_length,\n      'mel_scale': 'htk',\n    }\n)\n\nmfcc = mfcc_transform(waveform)\n\nplot_spectrogram(mfcc[0])","metadata":{"execution":{"iopub.status.busy":"2022-02-19T17:31:01.337003Z","iopub.execute_input":"2022-02-19T17:31:01.337347Z","iopub.status.idle":"2022-02-19T17:31:01.822518Z","shell.execute_reply.started":"2022-02-19T17:31:01.337311Z","shell.execute_reply":"2022-02-19T17:31:01.821558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"melspec = librosa.feature.melspectrogram(\n  y=waveform.numpy()[0], sr=sample_rate, n_fft=n_fft,\n  win_length=win_length, hop_length=hop_length,\n  n_mels=n_mels, htk=True, norm=None)\n\nmfcc_librosa = librosa.feature.mfcc(\n  S=librosa.core.spectrum.power_to_db(melspec),\n  n_mfcc=n_mfcc, dct_type=2, norm='ortho')\n\nplot_spectrogram(mfcc_librosa)\n\nmse = torch.square(mfcc - mfcc_librosa).mean().item()\nprint('Mean Square Difference: ', mse)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T17:31:23.530524Z","iopub.execute_input":"2022-02-19T17:31:23.530873Z","iopub.status.idle":"2022-02-19T17:31:23.870181Z","shell.execute_reply.started":"2022-02-19T17:31:23.530838Z","shell.execute_reply":"2022-02-19T17:31:23.869505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"waveform, sample_rate = get_speech_sample()\n\npitch = F.detect_pitch_frequency(waveform, sample_rate)\nplot_pitch(waveform, sample_rate, pitch)\nplay_audio(waveform, sample_rate)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T17:31:42.746824Z","iopub.execute_input":"2022-02-19T17:31:42.747716Z","iopub.status.idle":"2022-02-19T17:31:43.958404Z","shell.execute_reply.started":"2022-02-19T17:31:42.747662Z","shell.execute_reply":"2022-02-19T17:31:43.957624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"waveform, sample_rate = get_speech_sample(resample=16000)\n\npitch_feature = F.compute_kaldi_pitch(waveform, sample_rate)\npitch, nfcc = pitch_feature[..., 0], pitch_feature[..., 1]\n\nplot_kaldi_pitch(waveform, sample_rate, pitch, nfcc)\nplay_audio(waveform, sample_rate)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T17:32:28.809395Z","iopub.execute_input":"2022-02-19T17:32:28.809699Z","iopub.status.idle":"2022-02-19T17:32:30.337156Z","shell.execute_reply.started":"2022-02-19T17:32:28.809668Z","shell.execute_reply":"2022-02-19T17:32:30.33626Z"},"trusted":true},"execution_count":null,"outputs":[]}]}