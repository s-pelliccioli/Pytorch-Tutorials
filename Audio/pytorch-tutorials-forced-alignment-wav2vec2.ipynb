{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip3 install torch==1.10.2+cu102 torchvision==0.11.3+cu102 torchaudio===0.10.2+cu102 -f https://download.pytorch.org/whl/cu102/torch_stable.html\n\nimport os\nfrom dataclasses import dataclass\n\nimport torch\nimport torchaudio\nimport requests\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport IPython\n\nmatplotlib.rcParams['figure.figsize'] = [16.0, 4.8]\n\ntorch.random.manual_seed(0)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nprint(torch.__version__)\nprint(torchaudio.__version__)\nprint(device)\n\nSPEECH_URL = 'https://download.pytorch.org/torchaudio/tutorial-assets/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav'\nSPEECH_FILE = '_assets/speech.wav'\n\nif not os.path.exists(SPEECH_FILE):\n    os.makedirs('_assets', exist_ok=True)\n    with open(SPEECH_FILE, 'wb') as file:\n        file.write(requests.get(SPEECH_URL).content)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-20T18:57:09.195582Z","iopub.execute_input":"2022-02-20T18:57:09.196254Z","iopub.status.idle":"2022-02-20T18:59:45.240755Z","shell.execute_reply.started":"2022-02-20T18:57:09.196167Z","shell.execute_reply":"2022-02-20T18:59:45.239789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bundle = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H\nmodel = bundle.get_model().to(device)\nlabels = bundle.get_labels()\nwith torch.inference_mode():\n    waveform, _ = torchaudio.load(SPEECH_FILE)\n    emissions, _ = model(waveform.to(device))\n    emissions = torch.log_softmax(emissions, dim=-1)\n\nemission = emissions[0].cpu().detach()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:00:34.514383Z","iopub.execute_input":"2022-02-20T19:00:34.514666Z","iopub.status.idle":"2022-02-20T19:00:54.947969Z","shell.execute_reply.started":"2022-02-20T19:00:34.514636Z","shell.execute_reply":"2022-02-20T19:00:54.947273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(labels)\nplt.imshow(emission.T)\nplt.colorbar()\nplt.title(\"Frame-wise class probability\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"Labels\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:01:07.402154Z","iopub.execute_input":"2022-02-20T19:01:07.402792Z","iopub.status.idle":"2022-02-20T19:01:07.794923Z","shell.execute_reply.started":"2022-02-20T19:01:07.402752Z","shell.execute_reply":"2022-02-20T19:01:07.794085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transcript = 'I|HAD|THAT|CURIOSITY|BESIDE|ME|AT|THIS|MOMENT'\ndictionary  = {c: i for i, c in enumerate(labels)}\n\ntokens = [dictionary[c] for c in transcript]\nprint(list(zip(transcript, tokens)))\n\ndef get_trellis(emission, tokens, blank_id=0):\n    num_frame = emission.size(0)\n    num_tokens = len(tokens)\n\n    # Trellis has extra diemsions for both time axis and tokens.\n    # The extra dim for tokens represents <SoS> (start-of-sentence)\n    # The extra dim for time axis is for simplification of the code.\n    trellis = torch.full((num_frame+1, num_tokens+1), -float('inf'))\n    trellis[:, 0] = 0\n    for t in range(num_frame):\n        trellis[t+1, 1:] = torch.maximum(\n        # Score for staying at the same token\n        trellis[t, 1:] + emission[t, blank_id],\n        # Score for changing to the next token\n        trellis[t, :-1] + emission[t, tokens],\n        )\n    return trellis\n\ntrellis = get_trellis(emission, tokens)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:05:19.995101Z","iopub.execute_input":"2022-02-20T19:05:19.995539Z","iopub.status.idle":"2022-02-20T19:05:20.024575Z","shell.execute_reply.started":"2022-02-20T19:05:19.995505Z","shell.execute_reply":"2022-02-20T19:05:20.022775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(trellis[1:, 1:].T, origin='lower')\nplt.annotate(\"- Inf\", (trellis.size(1) / 5, trellis.size(1) / 1.5))\nplt.colorbar()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:06:00.602086Z","iopub.execute_input":"2022-02-20T19:06:00.602358Z","iopub.status.idle":"2022-02-20T19:06:00.866907Z","shell.execute_reply.started":"2022-02-20T19:06:00.602329Z","shell.execute_reply":"2022-02-20T19:06:00.866234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@dataclass\nclass Point:\n    token_index: int\n    time_index: int\n    score: float\n\n\ndef backtrack(trellis, emission, tokens, blank_id=0):\n    # Note:\n    # j and t are indices for trellis, which has extra dimensions\n    # for time and tokens at the beginning.\n    # When refering to time frame index `T` in trellis,\n    # the corresponding index in emission is `T-1`.\n    # Similarly, when refering to token index `J` in trellis,\n    # the corresponding index in transcript is `J-1`.\n    j = trellis.size(1) - 1\n    t_start = torch.argmax(trellis[:, j]).item()\n\n    path = []\n    for t in range(t_start, 0, -1):\n        # 1. Figure out if the current position was stay or change\n        # Note (again):\n        # `emission[J-1]` is the emission at time frame `J` of trellis dimension.\n        # Score for token staying the same from time frame J-1 to T.\n        stayed = trellis[t-1, j] + emission[t-1, blank_id]\n        # Score for token changing from C-1 at T-1 to J at T.\n        changed = trellis[t-1, j-1] + emission[t-1, tokens[j-1]]\n\n        # 2. Store the path with frame-wise probability.\n        prob = emission[t-1, tokens[j-1] if changed > stayed else 0].exp().item()\n        # Return token index and time index in non-trellis coordinate.\n        path.append(Point(j-1, t-1, prob))\n\n        # 3. Update the token\n        if changed > stayed:\n            j -= 1\n            if j == 0:\n                break\n    else:\n        raise ValueError('Failed to align')\n    return path[::-1]\n\npath = backtrack(trellis, emission, tokens)\nprint(path)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:10:25.079679Z","iopub.execute_input":"2022-02-20T19:10:25.080136Z","iopub.status.idle":"2022-02-20T19:10:25.099271Z","shell.execute_reply.started":"2022-02-20T19:10:25.080099Z","shell.execute_reply":"2022-02-20T19:10:25.098482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_trellis_with_path(trellis, path):\n    # To plot trellis with path, we take advantage of 'nan' value\n    trellis_with_path = trellis.clone()\n    for i, p in enumerate(path):\n        trellis_with_path[p.time_index, p.token_index] = float('nan')\n    plt.imshow(trellis_with_path[1:, 1:].T, origin='lower')\n\nplot_trellis_with_path(trellis, path)\nplt.title(\"The path found by backtracking\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:10:29.946312Z","iopub.execute_input":"2022-02-20T19:10:29.946822Z","iopub.status.idle":"2022-02-20T19:10:30.161264Z","shell.execute_reply.started":"2022-02-20T19:10:29.946787Z","shell.execute_reply":"2022-02-20T19:10:30.160609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Merge the labels\n@dataclass\nclass Segment:\n    label: str\n    start: int\n    end: int\n    score: float\n\n    def __repr__(self):\n        return f\"{self.label}\\t({self.score:4.2f}): [{self.start:5d}, {self.end:5d})\"\n\n    @property\n    def length(self):\n        return self.end - self.start\n\ndef merge_repeats(path):\n    i1, i2 = 0, 0\n    segments = []\n    while i1 < len(path):\n        while i2 < len(path) and path[i1].token_index == path[i2].token_index:\n            i2 += 1\n        score = sum(path[k].score for k in range(i1, i2)) / (i2 - i1)\n        segments.append(Segment(transcript[path[i1].token_index], path[i1].time_index, path[i2-1].time_index + 1, score))\n        i1 = i2\n    return segments\n\nsegments = merge_repeats(path)\nfor seg in segments:\n    print(seg)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:14:24.415091Z","iopub.execute_input":"2022-02-20T19:14:24.41536Z","iopub.status.idle":"2022-02-20T19:14:24.43158Z","shell.execute_reply.started":"2022-02-20T19:14:24.415332Z","shell.execute_reply":"2022-02-20T19:14:24.430809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_trellis_with_segments(trellis, segments, transcript):\n    # To plot trellis with path, we take advantage of 'nan' value\n    trellis_with_path = trellis.clone()\n    for i, seg in enumerate(segments):\n        if seg.label != '|':\n            trellis_with_path[seg.start+1:seg.end+1, i+1] = float('nan')\n\n    fig, [ax1, ax2] = plt.subplots(2, 1, figsize=(16, 9.5))\n    ax1.set_title(\"Path, label and probability for each label\")\n    ax1.imshow(trellis_with_path.T, origin='lower')\n    ax1.set_xticks([])\n\n    for i, seg in enumerate(segments):\n        if seg.label != '|':\n            ax1.annotate(seg.label, (seg.start + .7, i + 0.3), weight='bold')\n            ax1.annotate(f'{seg.score:.2f}', (seg.start - .3, i + 4.3))\n\n    ax2.set_title(\"Label probability with and without repetation\")\n    xs, hs, ws = [], [], []\n    for seg in segments:\n        if seg.label != '|':\n            xs.append((seg.end + seg.start) / 2 + .4)\n            hs.append(seg.score)\n            ws.append(seg.end - seg.start)\n            ax2.annotate(seg.label, (seg.start + .8, -0.07), weight='bold')\n    ax2.bar(xs, hs, width=ws, color='gray', alpha=0.5, edgecolor='black')\n\n    xs, hs = [], []\n    for p in path:\n        label = transcript[p.token_index]\n        if label != '|':\n            xs.append(p.time_index + 1)\n            hs.append(p.score)\n\n    ax2.bar(xs, hs, width=0.5, alpha=0.5)\n    ax2.axhline(0, color='black')\n    ax2.set_xlim(ax1.get_xlim())\n    ax2.set_ylim(-0.1, 1.1)\n\nplot_trellis_with_segments(trellis, segments, transcript)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:19:39.630619Z","iopub.execute_input":"2022-02-20T19:19:39.630878Z","iopub.status.idle":"2022-02-20T19:19:40.946595Z","shell.execute_reply.started":"2022-02-20T19:19:39.630851Z","shell.execute_reply":"2022-02-20T19:19:40.945949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Merge words\ndef merge_words(segments, separator='|'):\n    words = []\n    i1, i2 = 0, 0\n    while i1 < len(segments):\n        if i2 >= len(segments) or segments[i2].label == separator:\n            if i1 != i2:\n                segs = segments[i1:i2]\n                word = ''.join([seg.label for seg in segs])\n                score = sum(seg.score * seg.length for seg in segs) / sum(seg.length for seg in segs)\n                words.append(Segment(word, segments[i1].start, segments[i2-1].end, score))\n            i1 = i2 + 1\n            i2 = i1\n        else:\n            i2 += 1\n    return words\n\nword_segments = merge_words(segments)\nfor word in word_segments:\n    print(word)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:21:19.947463Z","iopub.execute_input":"2022-02-20T19:21:19.947722Z","iopub.status.idle":"2022-02-20T19:21:19.957016Z","shell.execute_reply.started":"2022-02-20T19:21:19.947694Z","shell.execute_reply":"2022-02-20T19:21:19.956297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_alignments(trellis, segments, word_segments, waveform):\n    trellis_with_path = trellis.clone()\n    for i, seg in enumerate(segments):\n        if seg.label != '|':\n            trellis_with_path[seg.start+1:seg.end+1, i+1] = float('nan')\n\n    fig, [ax1, ax2] = plt.subplots(2, 1, figsize=(16, 9.5))\n\n    ax1.imshow(trellis_with_path[1:, 1:].T, origin='lower')\n    ax1.set_xticks([])\n    ax1.set_yticks([])\n\n    for word in word_segments:\n        ax1.axvline(word.start - 0.5)\n        ax1.axvline(word.end - 0.5)\n\n    for i, seg in enumerate(segments):\n        if seg.label != '|':\n            ax1.annotate(seg.label, (seg.start, i + 0.3))\n            ax1.annotate(f'{seg.score:.2f}', (seg.start , i + 4), fontsize=8)\n\n    # The original waveform\n    ratio = waveform.size(0) / (trellis.size(0) - 1)\n    ax2.plot(waveform)\n    for word in word_segments:\n        x0 = ratio * word.start\n        x1 = ratio * word.end\n        ax2.axvspan(x0, x1, alpha=0.1, color='red')\n        ax2.annotate(f'{word.score:.2f}', (x0, 0.8))\n\n    for seg in segments:\n        if seg.label != '|':\n            ax2.annotate(seg.label, (seg.start * ratio, 0.9))\n    xticks = ax2.get_xticks()\n    plt.xticks(xticks, xticks / bundle.sample_rate)\n    ax2.set_xlabel('time [second]')\n    ax2.set_yticks([])\n    ax2.set_ylim(-1.0, 1.0)\n    ax2.set_xlim(0, waveform.size(-1))\n\nplot_alignments(trellis, segments, word_segments, waveform[0],)\nplt.show()\n\n# A trick to embed the resulting audio to the generated file.\n# `IPython.display.Audio` has to be the last call in a cell,\n# and there should be only one call par cell.\ndef display_segment(i):\n    ratio = waveform.size(1) / (trellis.size(0) - 1)\n    word = word_segments[i]\n    x0 = int(ratio * word.start)\n    x1 = int(ratio * word.end)\n    filename = f\"_assets/{i}_{word.label}.wav\"\n    torchaudio.save(filename, waveform[:, x0:x1], bundle.sample_rate)\n    print(f\"{word.label} ({word.score:.2f}): {x0 / bundle.sample_rate:.3f} - {x1 / bundle.sample_rate:.3f} sec\")\n    return IPython.display.Audio(filename)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:23:25.027245Z","iopub.execute_input":"2022-02-20T19:23:25.027693Z","iopub.status.idle":"2022-02-20T19:23:26.071789Z","shell.execute_reply.started":"2022-02-20T19:23:25.027657Z","shell.execute_reply":"2022-02-20T19:23:26.071134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate the audio for each segment\nprint(transcript)\nIPython.display.Audio(SPEECH_FILE)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:23:55.451249Z","iopub.execute_input":"2022-02-20T19:23:55.451532Z","iopub.status.idle":"2022-02-20T19:23:55.463173Z","shell.execute_reply.started":"2022-02-20T19:23:55.451505Z","shell.execute_reply":"2022-02-20T19:23:55.462314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_segment(3)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:24:38.673113Z","iopub.execute_input":"2022-02-20T19:24:38.673379Z","iopub.status.idle":"2022-02-20T19:24:38.682748Z","shell.execute_reply.started":"2022-02-20T19:24:38.67335Z","shell.execute_reply":"2022-02-20T19:24:38.681848Z"},"trusted":true},"execution_count":null,"outputs":[]}]}